[
  {
    "objectID": "post/2021-04-12-a-first-look-at-tattoos-in-the-digital-panopticon/index.html",
    "href": "post/2021-04-12-a-first-look-at-tattoos-in-the-digital-panopticon/index.html",
    "title": "A first look at tattoos in the Digital Panopticon",
    "section": "",
    "text": "This post is an introduction to, firstly, the newly-released Tattoos in the Digital Panopticon Database, 1793-1925; and, secondly, to the software and code being used to analyse the data.\nThe dataset contains about 195,000 physical descriptions of convicts and prisoners. About 75,000 of these have been identified as containing tattoos, representing about 58,000 individuals (according to DP record linkage), and somewhere in the region of 350,000 discrete tattoos.\nThe dataset is derived from types of source material that many historians are more likely to encounter than the narrative and printed texts that are common in Digital Humanities research: local and central registers, files, forms and other early modern and modern archival records which are full of information that is neither free-flowing prose nor quite structured enough to be easy to extract computationally. Such data is still most likely to be compiled laboriously by hand.\nWe didn’t have the resources to do that, and this dataset simply can’t be as accurate as a manually-created one. Our goal was to make it good enough to use for large scale quantitative analysis, in which the imperfections taken as a whole are too small to significantly change results, and exploratory analyses that will help to provoke ideas and provide pointers to dig deeper into the mass of data.\nWe’ve made the data openly available - all the descriptions, not just those in which we identified tattoos, and including the transcriptions as well as the extracted tattoo data - for several reasons:\n\ntransparency about the limitations of the data\naiding others to improve on our work\nfacilitate testing of the project’s research findings\nenable other re-uses and explorations of the data\n\nThe dataset also contains information that will aid users to locate the records at the Digital Panopticon website and from there, if desired, find digitised images of the originals (but note that in many cases the images are behind paywalls)."
  },
  {
    "objectID": "post/2021-04-12-a-first-look-at-tattoos-in-the-digital-panopticon/index.html#the-background",
    "href": "post/2021-04-12-a-first-look-at-tattoos-in-the-digital-panopticon/index.html#the-background",
    "title": "A first look at tattoos in the Digital Panopticon",
    "section": "The background",
    "text": "The background\nThe Digital Panopticon 1780-1925 is an ambitious large-scale digital history project to investigate the relative impacts of different types of punishment on criminal desistance, health outcomes, employment opportunities, and family life over the long term, using record linkage on more than 50 existing and newly-digitised datasets including the Proceedings of the Old Bailey, Founders and Survivors, commercially digitised genealogical data on criminals and prisoners in 19th-century Britain, and civil data on births, marriages and deaths.\nThe project’s central focus was on tens of thousands of Londoners sentenced to imprisonment or transportation at the Old Bailey between 1780 and 1885, though the nature of the data entailed collecting information on many more prisoners and convicts in Britain and Australia. Ultimately, the Digital Panopticon web resource, launched in September 2017, contained almost 4 million records dating from the mid 18th century to the early 20th century.\nMany of these datasets contain information relating to the physical characteristics of individuals. DP’s main interest in this kind of data was for biometric analysis of heights and ages. However, some records also contain much more detailed but less structured descriptions of “distinguishing marks”, including scars from injuries, marks of past diseases and corporal punishments, and more voluntarily acquired markings.\nAlmost accidentally, DP created a huge database of tattooing practices in Britain and Australia from the end of the 18th century to the early 20th century, but one that was not easily usable because of the diverse, composite nature of the fields containing the material. The Criminal Tattoos project’s goal has been to find ways to make this information more accessible, and to explore ways of analysing and visualising it."
  },
  {
    "objectID": "post/2021-04-12-a-first-look-at-tattoos-in-the-digital-panopticon/index.html#purpose-of-the-blog-posts",
    "href": "post/2021-04-12-a-first-look-at-tattoos-in-the-digital-panopticon/index.html#purpose-of-the-blog-posts",
    "title": "A first look at tattoos in the Digital Panopticon",
    "section": "Purpose of the blog posts",
    "text": "Purpose of the blog posts\nThis and subsequent blog posts aren’t primarily about the project’s research, which is introduced here and is in the process of being submitted to journals. Instead, I have three main goals.\nOne is to facilitate and encourage creative re-uses of the dataset (which is itself already the outcome of many re-uses, bringing together data created by several projects in different ways over almost two decades). I don’t think it’s enough to just release the data with technical documentation, and leave it at that. It isn’t a particularly easy dataset to work with, because of its size and complexity. So I’ll introduce some aspects of the data with examples of what I’ve been doing to inform the project research over the last 18 months.\nI’ll also use it to document at least some of the visualisations that we’ve already shared at the DP visualisations gallery.\nA second (but related) goal is to make historians more aware of different ways of using visualisation techniques, beyond the familiar simple bar or line graph, especially for uncovering complex patterns in multivariate data.\nMore specifically, I want to introduce the tools and methods I’ve been using to analyse and visualise the data, and to provide practical examples for historians, both for this and similar kinds of datasets. I hope to show how R can be an effective tool for working with complex historical datasets, and how it might be worth the time and effort needed to learn how to use it.\n(This doesn’t mean I think R is “better” than, say, Python or another language. I do think programming languages tend to have different strengths, not least the communities that have grown around them and the resources those communities create for them. My opinion is that Python is especially strong for processing and analysing large corpora of relatively unstructured texts (and in fact the extraction/processing side of the project was done using Python); where R is particularly useful for analysing and visualising large and complex but more structured data. Moreover, I’m currently much more competent and comfortable using R and the limited time available for this project meant I needed that. So R was a better fit for this particular project.)\n\nR, RMarkdown and the “Tidyverse”\nAll the posts are being written in RMarkdown, as notebooks that weave together narrative text and chunks of code. They are then turned into HTML webpages for the blog (but could alternatively be turned into Word docs, or PDFs, or presentation slides).\nThus, the posts will include plenty of code and some explanations. However, they aren’t intended to be step-by-step tutorials of which there are plenty online. I recommend these as good starting points:\n\nR Basics with Tabular Data (Programming Historian)\nData Wrangling and Management in R (Programming Historian)\n(which can be followed by various other R lessons at the Programming Historian)\n\nAnd this more comprehensive (free) guide book:\n\nR for Data Science (Hadley Wickham)\n\nNonetheless I think I should set out a few of the basic concepts here. I’m using a particular variant of the wider R ecosystem, which works by linking together a sequence of verbal commands with a “pipe” symbol %>%. The core functions - like “verbs” - for the work of tidying, reshaping, grouping and summarising data for quantitative analysis are:\n\nselect() - specify columns in the data table to work with (useful if there are a lot of them!)\nfilter() - limit analysis to specified rows of data\narrange() - re-sort them\nmutate() - create new columns, by doing some operation on the existing columns\nsummarise() - collapse many values down to a single summary value\ngroup_by() - group rows of data together in preparation for some further summarise/mutate command\n..._join() - a set of verbs for linking related tables together\n\n(I find this flavour of R particularly congenial because I came to the language from using MySQL, which operates in a similar way. Others are available.)\nSome other R terminology:\n\nobject: objects can be all sorts of things in R, from a single number to a string of characters to a data table to a nested list of things, and other highly specialised data formats; but the key feature is that they’ve been named and saved for re-use in a script, so you can for example avoid having to re-import a file every time you want to do something to it\npackage: like many modern programming languages and software tools, R has a relatively limited core functionality (“base R”) which is then extended by third-party developers to provide convenient tools for particular uses. Most readers will be familiar with this concept even if they have different names in different tools - extensions, plugins, libraries, etc. In R packages is the usual term, often denoted by writing the name in {curly brackets}. (You can also get data packages which bundle up datasets in a convenient ready-made R format.)"
  },
  {
    "objectID": "post/2021-04-12-a-first-look-at-tattoos-in-the-digital-panopticon/index.html#the-health-warnings",
    "href": "post/2021-04-12-a-first-look-at-tattoos-in-the-digital-panopticon/index.html#the-health-warnings",
    "title": "A first look at tattoos in the Digital Panopticon",
    "section": "The health warnings",
    "text": "The health warnings\nUsers of the data should be aware from the outset that the dataset is a very long way from perfect; extracting tattoos from the descriptions was a major challenge for a small project with limited funding. It is likely that many tattoos (especially the “long tail” of rare tattoo designs) have been missed, and conversely things that were not tattoos have been misidentified. The process aimed not simply to find tattoos but also to associate them with body locations, and this could also go wrong in various ways.\nThe extraction methodology is described in some detail on the DP website, so I’m not going to repeat it here. But this is the sort of thing the project had to grapple with (tattoo elements highlighted):\n\nCrucifix above elbow Joint rt arm deep dimple on chin Scar near outer corner rt eye Moon & 7 stars JW mermaid anchor JC MD JD TD & Cannon (Prop) inside rt arm [James Rees, transported to Tasmania 1826]\n\n\nScar forehead, right eyebrow, right ear, left cheek, left side of nose, both sides of neck, lip, right arm elbow, right leg, right shoulder. I.L.M.K Liverpool E.R on right arm, ears pierced, lost several teeth. [Bridget Lacking, sentenced to penal servitude 1881]\n\n\nscar right cheek and several back and loins ; female and barge left forearm ; half bracelet left wrist; birthniark left groin. [Henry Palmer, register of habitual criminals 1899 and 1901]\n\nThere are various problems. They’re a rather undifferentiated stream of small pieces of information, not in any fixed order, not all tattoos, and on occasion not actually about physical characteristics at all. Punctuation is unreliable, if it’s used at all. Abbreviations (such as “r” or “rt” for right and of course “&” for and) are very common and also quite variable. There can, of course, also be transcription errors.\nIf a person had several tattoos on one part of the body, they’d usually be grouped together, so attaching a design to the right location is also not a simple exercise (oh, and the body part might sometimes be written before the tattoos, rather than afterwards as in these examples).\nEven after isolating tattoos from other strings of text, it often isn’t easy to define a single “tattoo”. You need to know that “Moon & 7 stars” is a religious symbol and so probably not two separate tattoos. It’s one of many phrases that have been identified as such. But what about something like “female and barge”? This might have been something like a picture of a woman on a barge or might be two separate tattoos “a woman” and “a barge”; in the data it’s the latter. There’s no way we could identify every possible phrase or combination of things that were originally a single tattoo design.\nAnd it must be emphasised that in the vast majority of cases we have no idea what the tattoos actually looked like. (In a very few cases the original records contain tiny sketched drawings of the tattoos, which have been transcribed as text if they could be interpreted.) The data is entirely based on written descriptions, written down by many different officials over a long period of time, with undoubtedly hugely varying degrees of diligence and competence."
  },
  {
    "objectID": "post/2021-04-12-a-first-look-at-tattoos-in-the-digital-panopticon/index.html#the-convict-descriptions-data",
    "href": "post/2021-04-12-a-first-look-at-tattoos-in-the-digital-panopticon/index.html#the-convict-descriptions-data",
    "title": "A first look at tattoos in the Digital Panopticon",
    "section": "The convict descriptions data",
    "text": "The convict descriptions data\nThe dataset contains two CSV files. Here I’m focusing on convict_descriptions, which contains 241207 rows of data. The second, convict_description_segments has more detailed information about the bodily locations of tattoos; I’ll get to that in a later post.\nThe first thing to do is load the R packages needed for analysis using the library() function. For now, I just want one, {tidyverse}, though that’s really a big convenience package of related sub-packages.\n\n# the # is used to insert comments, so R will ignore them when it executes the code\n# this helps to remind you what on earth you were trying to do, when you have to read your code again later\n# or to enable other people reading your code to understand what you're trying to do\n\n# the library() function is used to load packages that aren't part of the R core. \n\nlibrary(tidyverse)\n\nNext, import the data (with the read_csv() function). (An important principle here is that you import a copy of your data and then work with it entirely inside R; you don’t do anything to the original data file.)\n\n# <-  is used to create a new object\n\ndescriptions_data <- \n  read_csv(here::here(\"_data\", \"convict_descriptions.2020-12-17.csv\"), guess_max = 100000)\n\nNow I can take a glimpse() at it: there is a lot of stuff in there. 42 columns of data!\n\ndescriptions_data %>% \n  glimpse()\n\nRows: 241,207\nColumns: 42\n$ subrecordid                      <chr> \"cin77589\", \"cin77590\", \"cin77591\", \"…\n$ recordid                         <chr> \"cin77589\", \"cin77590\", \"cin77591\", \"…\n$ life_id                          <chr> \"cin77589\", \"cin77590\", \"cin77591\", \"…\n$ descyear                         <dbl> 1850, 1850, 1850, 1850, 1850, 1850, 1…\n$ dataset                          <chr> \"cin\", \"cin\", \"cin\", \"cin\", \"cin\", \"c…\n$ hastattoo                        <chr> \"y\", \"y\", \"n\", \"y\", \"n\", \"n\", \"n\", \"n…\n$ haspunishmentmark                <chr> \"n\", \"n\", \"n\", \"n\", \"n\", \"n\", \"n\", \"n…\n$ desc_count                       <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ designs                          <chr> \"anchor|dog|moon|man and woman|diamon…\n$ writtenwords                     <chr> \"IMB|ST\", \"JP|CPEP\", NA, \"EM|LARK\", N…\n$ writtenyears                     <chr> \"1838\", NA, NA, NA, NA, NA, NA, NA, N…\n$ punishmentmarks                  <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ body                             <chr> \"right arm|left arm\", \"right hand|rig…\n$ digest                           <chr> \"[right arm : man and woman|sun|dog|S…\n$ subjects                         <chr> \"love year astronomy namesinitials pl…\n$ url                              <chr> \"https://www.digitalpanopticon.org/li…\n$ fulldescription                  <chr> \"Man and woman, 2 stars, 1 dog, ST 18…\n$ given                            <chr> \"Samuel\", \"John\", \"William\", \"John\", …\n$ surname                          <chr> \"Scattergood\", \"Patience\", \"Branson\",…\n$ gender                           <chr> \"m\", \"m\", \"m\", \"m\", \"m\", \"m\", \"m\", \"m…\n$ born                             <dbl> 1814, 1820, 1817, 1820, 1824, 1826, 1…\n$ transported                      <chr> \"yes\", \"yes\", \"yes\", \"yes\", \"yes\", \"y…\n$ ticket_of_leave                  <chr> \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"…\n$ penalservitude                   <chr> \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"…\n$ granted_prison_license           <chr> \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"…\n$ married                          <chr> \"unknown\", \"unknown\", \"unknown\", \"unk…\n$ insane                           <chr> \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"…\n$ in_hulks                         <chr> \"unknown\", \"unknown\", \"unknown\", \"unk…\n$ religion                         <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ religion_category                <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ occupation                       <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ occupation_top_50                <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ hisco                            <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ place_of_birth                   <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ship                             <chr> \"scindian\", \"scindian\", \"scindian\", \"…\n$ earliest_trial_offence_category  <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ earliest_trial_sentence_category <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ latest_trial_offence_category    <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ latest_trial_sentence_category   <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ trials                           <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ earliest_trial                   <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ latest_trial                     <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n\n\nThat’s because, as well as the descriptions and tattoos, we included various pieces of information about the individuals drawn from the DP database. Very often, this has come from the same record as the description (if a record was detailed enough to contain physical descriptions, it probably also had quite a lot of other personal information). Some of it, on the other hand, is drawn from a larger life archive of linked records for an individual. (You can read the dataset documentation for more detail.) I’m going to ignore most of it in this post. But at least a few explanations are in order now.\n\nidentifiers\nThere are three ID columns, all based on Digital Panopticon’s own IDs. Generally you’ll only need to work with two of them.\n\nsubrecordid is the unique identifier for each record in the table\nlife_id is the ID for a person, more precisely what DP calls a “life archive”, which links together all the records for the same individual (we hope; and in practice, we have only a single record for many individuals).\n\nIt can be quite important to bear in mind the distinctions between people, records, descriptions and tattoos in the data. One record = one row in the table. A person can have multiple records, not all of which contain a description, and descriptions don’t all contain any tattoos.\n(The third ID column is recordid and this is nearly - but not quite - always identical to subrecordid. You’re very unlikely to need it. The reason it exists separately is because some records have come from complex relational databases in which an individual could have several description records, from different tables. Thus the recordid is the ID for that database record as a whole, whereas subrecordid gives each of the descriptions a unique identifier.)\nSo, how many individual people (according to DP’s record linkage) and how many records in total are there in the dataset?\n\ndescriptions_data %>%\n  # n_distinct() is a function to count *unique* values; n() counts *all* values\n  summarise(n_life_id = n_distinct(life_id), \n            n_total = n()\n            )\n\n# A tibble: 1 × 2\n  n_life_id n_total\n      <int>   <int>\n1    193460  241207\n\n\n\n\nDP datasets\nThe column dataset is the short code for each… errmmm… dataset in the… errrmmm… dataset. (Perhaps we didn’t think some of the naming through as well as we could have done.) In fact this refers to the datasets in the Digital Panopticon. Just to confuse everyone a bit further, they’re grouped slightly differently here, so we’ve got 8 datasets where there are only six in DP itself.\n\ndescriptions_data %>%\n  distinct(dataset) %>%\n  arrange(dataset)\n\n# A tibble: 8 × 1\n  dataset\n  <chr>  \n1 cin    \n2 fas    \n3 fas_pgo\n4 hcr    \n5 mpr    \n6 pld    \n7 rhc    \n8 tlm    \n\n\nIn DP, fas + fas_pgo are treated as a single dataset, as are pld + tlm. The full names are in the Tattoos database documentation, though I’ll be coming back to them briefly before the end of the post.\nHow many descriptions are there in each dataset? For this I need to use group_by(), to group together rows from the same dataset, before I can summarise().\n\ndescriptions_data %>%\n  group_by(dataset) %>%\n  summarise(n_records = n()) %>%\n  ungroup()\n\n# A tibble: 8 × 2\n  dataset n_records\n  <chr>       <int>\n1 cin          9719\n2 fas         76830\n3 fas_pgo     10587\n4 hcr            12\n5 mpr           914\n6 pld           882\n7 rhc        135996\n8 tlm          6267\n\n\nBut I can also - and most often do because it’s shorter and I’m lazy - do exactly the same thing with another handy function, count(). (sort=TRUE is ordering the results by count rather than alphabetically.)\n\ndescriptions_data %>%\n  count(dataset, name=\"n_records\", sort=TRUE)\n\n# A tibble: 8 × 2\n  dataset n_records\n  <chr>       <int>\n1 rhc        135996\n2 fas         76830\n3 fas_pgo     10587\n4 cin          9719\n5 tlm          6267\n6 mpr           914\n7 pld           882\n8 hcr            12\n\n\nThey vary somewhat in size!\n\n\ntattoos\nThere are nine columns related to the actual descriptions and tattoos extracted from them.\n\nhastattoo\ndesigns\nwrittenwords\nwrittenyears\nbody\ndigest\nsubjects\nfulldescription\ndesc_count\n\nhastattoo tells you a) whether there is text in the description field (“u” means that it’s blank) and b) whether we identified any tattoos in the description if present (“y” for yes; “n” for no).\n\ndescriptions_data %>%\n  count(hastattoo)\n\n# A tibble: 3 × 2\n  hastattoo      n\n  <chr>      <int>\n1 n         118850\n2 u          46909\n3 y          75448\n\n\nAnd I can quickly plot that…\n\ndescriptions_data %>%\n  count(hastattoo) %>%\n  mutate(hastattoo = fct_relevel(hastattoo, \"n\", \"y\")) %>%\n  ggplot(aes(x=hastattoo, y=n)) +\n  geom_col()\n\n\n\n\ndesc_count is the number of separate records for the individual person to whom the record belongs. Out of curiosity, how many individuals have more than one record?\n\ndescriptions_data %>%\n  filter(desc_count>1) %>% \n  summarise(n=n_distinct(life_id))\n\n# A tibble: 1 × 1\n      n\n  <int>\n1 24127\n\n\nI don’t tend to use desc_count, because I can calculate it for myself using life_id. But it’s quite handy for some questions.\nWhat’s the top number of records for one individual?\n\ndescriptions_data %>%\n  count(life_id) %>%\n  top_n(1, n)\n\n# A tibble: 1 × 2\n  life_id     n\n  <chr>   <int>\n1 fas2916    50\n\n\nHow many records do most individuals have?\n\ndescriptions_data %>%\n  distinct(life_id, desc_count) %>%\n  count(desc_count, name=\"n_records\", sort = TRUE) %>%\n  filter(desc_count<=10)\n\n# A tibble: 10 × 2\n   desc_count n_records\n        <dbl>     <int>\n 1          1    169333\n 2          2     14009\n 3          3      4981\n 4          4      2244\n 5          5      1201\n 6          6       670\n 7          7       368\n 8          8       204\n 9          9       129\n10         10        82\n\n\nHow many records containing descriptions do most have?\n\ndescriptions_data %>%\n  filter(hastattoo !=\"u\") %>% \n  # filter(!is.na(fulldescription)) would give the same result\n  distinct(life_id, desc_count) %>%\n  count(desc_count, name=\"n_records_with_desc\", sort = TRUE) %>%\n  filter(desc_count<=10)\n\n# A tibble: 10 × 2\n   desc_count n_records_with_desc\n        <dbl>               <int>\n 1          1              129122\n 2          2               13525\n 3          3                4907\n 4          4                2222\n 5          5                1192\n 6          6                 664\n 7          7                 364\n 8          8                 204\n 9          9                 129\n10         10                  82\n\n\nHow many records containing tattoos?\n\ndescriptions_data %>%\n  filter(hastattoo ==\"y\") %>% \n  # filter(!is.na(fulldescription)) would give the same answer\n  distinct(life_id, desc_count) %>%\n  count(desc_count, name=\"n_records_with_tattoos\", sort = TRUE) %>%\n  filter(desc_count<=10)\n\n# A tibble: 10 × 2\n   desc_count n_records_with_tattoos\n        <dbl>                  <int>\n 1          1                  45363\n 2          2                   6570\n 3          3                   2738\n 4          4                   1313\n 5          5                    728\n 6          6                    423\n 7          7                    224\n 8          8                    122\n 9          9                     81\n10         10                     55\n\n\nsubjects refers to a set of broad categories for tattoos (eg “nationalidentity” or “pleasure”); they’re a bit different from the rest in that project staff manually decided on the assignment of subjects to tattoo designs. You should be aware that it’s a summary of all the subjects for the description, not just for a single tattoo, and the column can contain a list of several subjects.\nfulldescription is the original transcription of the description; designs, writtenwords and writtenyears are tattoo classifications; body and digest both relate to the location of tattoos on the body.\nFinally, there are various pieces of demographic and offending history (eg gender, birth place) drawn from the DP records."
  },
  {
    "objectID": "post/2021-04-12-a-first-look-at-tattoos-in-the-digital-panopticon/index.html#two-visualisations",
    "href": "post/2021-04-12-a-first-look-at-tattoos-in-the-digital-panopticon/index.html#two-visualisations",
    "title": "A first look at tattoos in the Digital Panopticon",
    "section": "Two visualisations",
    "text": "Two visualisations\nI want to finish this post by reproducing two visualisations I made for the project’s page at DP.\nFirst, there was a bar chart of the number of tattooed people per dataset:\n\nThe steps for this are as follows\n\nfilter to use only descriptions with tattoos\nrecode the dataset names where needed before grouping them\ncount unique life ids (so I get the number of people, not the number of descriptions)\nmake nice labels\nmake the chart\n\n\ndescriptions_filter_mutate_group_summarise <-\ndescriptions_data %>%\n  filter(hastattoo==\"y\") %>%\n    # case_when() enables you to change data depending on specified conditions\n  mutate(dataset = case_when(\n    dataset ==\"tlm\" ~ \"pld\",  # if the dataset = tlm, change to pld (ie, merging them together)\n    dataset ==\"fas_pgo\" ~ \"fas\", # change fas_pgo to fas\n    TRUE ~ dataset  # otherwise, leave unchanged\n  )) %>%\n  group_by(dataset) %>%\n  summarise(n = n_distinct(life_id)) %>%\n  ungroup()\n\ndescriptions_filter_mutate_group_summarise %>%\n  arrange(-n)\n\n# A tibble: 6 × 2\n  dataset     n\n  <chr>   <int>\n1 rhc     41948\n2 fas     12538\n3 cin      2381\n4 pld       849\n5 mpr        68\n6 hcr        12\n\n\nNow the list of the dataset names for the labels.\n\ndataset_labels <- c(\"HO Criminal Registers\", \"Millbank Prison Register\", \"Convict Licences\",  \"WA Convict Indents\",  \"Founders and Survivors\", \"Register of Habitual Criminals\")\n\ndataset_labels\n\n[1] \"HO Criminal Registers\"          \"Millbank Prison Register\"      \n[3] \"Convict Licences\"               \"WA Convict Indents\"            \n[5] \"Founders and Survivors\"         \"Register of Habitual Criminals\"\n\n\nTo make the chart I use a package called {ggplot2} (which is included in the Tidyverse so I don’t need to load it separately). ggplot is advertised as “a grammar of graphics”, which should give a sense of how it works - rather like Tidyverse R as a whole. The different elements or layers of a chart are coded in separate steps, including\n\ngeom_ to set the type of chart (bar, line, dot, etc)\nscale_ to handle axis and legend formatting, labelling and so on\nfacet_ to split a chart into subcharts (aka “small multiples”)\ntheme_ provides some convenient packages for overall aesthetics\n\n\ndescriptions_filter_mutate_group_summarise %>%\n  mutate(dataset = fct_reorder(dataset, n)) %>% # put the bars in the order I want in the chart\n  \n  ggplot(aes(x=dataset, y=n, fill=dataset)) + # set up the data for ggplot\n  geom_col(show.legend = FALSE) + # draw a bar chart\n  coord_flip() + # make the bars horizontal (some of the labels are quite long and it looks better)\n  scale_fill_brewer(palette = \"Reds\") + # add some colours to the bars; purely cosmetic here\n  scale_x_discrete(labels=dataset_labels) + # add the labels\n  theme_minimal() + \n  labs(y=\"number of convicts\", x=NULL, title=\"Number of Tattooed Convicts by Dataset\") # titles \n\n\n\n\nThe second bar chart showed the frequencies of tattoo subjects.\n\nThis will be quite similar to the first chart, but the subjects column can contain several subjects, not just one.\n\ndescriptions_data %>%\n  filter(hastattoo==\"y\") %>%\n  # not all tattoos have subjects assigned; filter out the empty ones\n  filter(!is.na(subjects)) %>% \n  select(subjects) %>%\n  # just get the first six rows for a quick look\n  head() \n\n# A tibble: 6 × 1\n  subjects                                        \n  <chr>                                           \n1 love year astronomy namesinitials pleasure naval\n2 namesinitials                                   \n3 namesinitials naval                             \n4 namesinitials                                   \n5 love naval religion                             \n6 jewellery                                       \n\n\nSo I need to reshape the data so there’s just one subject per line before counting them; I’ll do this with a function called unnest_tokens() from the excellent {tidytext} package.\nSo, the steps for this one:\n\nget descriptions with tattoos only\nfilter out those without any subjects assigned\nseparate out lists of subjects into one subject per line\nget the summary counts\n\n\nlibrary(tidytext)\n\ndescriptions_subjects_tokenised <-\ndescriptions_data %>%\n  filter(hastattoo==\"y\", !is.na(subjects)) %>%\n  select(subrecordid, subjects) %>%\n  unnest_tokens(subject, subjects) %>%\n  count(subject, sort=TRUE)\n\ndescriptions_subjects_tokenised\n\n# A tibble: 19 × 2\n   subject               n\n   <chr>             <int>\n 1 namesinitials     41832\n 2 naval             21417\n 3 religion          14412\n 4 love              14342\n 5 jewellery         13154\n 6 nationalidentity  11948\n 7 nature            11082\n 8 astronomy          7113\n 9 death              4366\n10 britain            3879\n11 pleasure           3237\n12 military           2628\n13 year               1295\n14 ireland            1211\n15 america            1165\n16 justicepunishment   439\n17 sex                 205\n18 invention            49\n19 australia            10\n\n\nAnd now to draw the chart:\n\ndescriptions_subjects_tokenised %>%\n  mutate(subject = fct_reorder(subject, n)) %>%\n    ggplot(aes(subject, n)) +\n    geom_col() +\n    coord_flip() +\n    theme_minimal() +\n    labs(y = \"number of subjects\",  x = NULL, title=\"Frequencies of Tattoo Subjects\")"
  },
  {
    "objectID": "post/2020-12-21-data-release-tattoos-in-the-digital-panopticon-database-1793-1925/index.html",
    "href": "post/2020-12-21-data-release-tattoos-in-the-digital-panopticon-database-1793-1925/index.html",
    "title": "Data Release: Tattoos in the Digital Panopticon Database, 1793-1925",
    "section": "",
    "text": "I’m delighted to be able to announce that we’ve shared the project data under a Creative Commons licence and it’s now available for download from the University of Sheffield data repository:\nTattoos in the Digital Panopticon database, 1793-1925\nI’ll be blogging about this soon; here’s a taster of what’s to come…"
  },
  {
    "objectID": "post/2021-06-19-come-together-joining-data-tables/index.html",
    "href": "post/2021-06-19-come-together-joining-data-tables/index.html",
    "title": "Come TogetheR: Combining data tables in R with dplyr join verbs",
    "section": "",
    "text": "Combining or joining data tables using a shared key (or ID) column is crucial for working with many kinds of datasets, but is not often well understood by historians.\nThis is unfortunate, because many historical sources are too complex to fit comfortably into simple “rectangular” formats like spreadsheets. They contain what are known as “one-to-many” or even “many-to-many” relationships. An example of this from the Old Bailey Proceedings is that one trial (the main unit in the database) can contain\n\nmany defendants\nmany offences\nmany verdicts\nmany sentences\n\nBut a tabular data format can only easily handle “one-to-one” relationships: one trial would have just one defendant, one offence, one verdict and one sentence.\nThere are a couple of workarounds commonly used when entering data like this into a spreadsheet: you might put multiple items in one column, or add extra numbered columns (eg “offence_1”, “offence_2”, etc). The latter soon gets unwieldy if you need more than a couple of columns, and it’s difficult to analyse a variable that’s been spread across several different columns. The first approach can also be clumsy and is definitely not “tidy”, resulting in a mixed-up bag of things in a single column (my previous post on tidying data showed a way to deal with that problem).\nA common approach to storing more complex data like this is to use a relational database with several linked tables. The two data tables in the tattoos database are linked in this way, with a one-to-many relationship between the two data tables: the descriptions are the main unit of data, but the body segments data can contain several segments per description. However, in this case, a decision was made to duplicate much of the descriptions table information (mostly biographical) in the segments table, which largely removes any need for joins.\nBut the downside is that all the duplicated information in the segments table takes up a lot of space and slows down importing data. I found this annoying, so I created a substantially slimmed-down version of the segments table by removing most of the description-level information that’s duplicated in the descriptions table. This reduced a 310 MB file to 87 MB! Then I use joins as and when I actually need data from both tables in an analysis. I’ll be using my skinny version of the data in examples in this post."
  },
  {
    "objectID": "post/2021-06-19-come-together-joining-data-tables/index.html#combining-data",
    "href": "post/2021-06-19-come-together-joining-data-tables/index.html#combining-data",
    "title": "Come TogetheR: Combining data tables in R with dplyr join verbs",
    "section": "Combining data",
    "text": "Combining data\nThere are in fact a number of different ways of combining data tables, horizontally or vertically. In R, one of them is more often known as “binding”, by rows or columns. A common use for {dplyr’s} bind_rows() function, which simply adds one table to the bottom of another table, is where collection of the same (or very similar) data source was split into separate tables.\nTo combine two tables side-by-side, the equivalent is bind_cols(). But this can only be used where the two tables have exactly the same number of rows, and you have to be sure that your two tables are an exactly matching pair, with the rows on each side of the pair in the same order.\n“Joining” as defined here also combines two tables side-by-side. But other than that, it works quite differently. Unlike bind_cols(), the order of the rows in each table doesn’t matter, and they don’t even need to have the same number of rows. But they do have to contain at least one shared “key”.\n\nA key is a variable (or set of variables) that uniquely identifies an observation."
  },
  {
    "objectID": "post/2021-06-19-come-together-joining-data-tables/index.html#the-data",
    "href": "post/2021-06-19-come-together-joining-data-tables/index.html#the-data",
    "title": "Come TogetheR: Combining data tables in R with dplyr join verbs",
    "section": "The data",
    "text": "The data\nFirst, I’ll load the R packages I need and the two data files, the original descriptions and the slimmed-down segments. (For more info about the dataset, see the introductory post.) The skinny segments data is available here.\n\nlibrary(tidyverse)\nlibrary(scales)\nlibrary(tidytext)\nlibrary(ggthemes)\ntheme_set(theme_minimal())\n\ndescriptions_data <- \n  read_csv(here::here(\"_data\", \"convict_descriptions.2020-12-17.csv\"), guess_max = 100000)\n\nsegments_data <-\n  read_csv(here::here(\"_data\", \"body_segments_20210327.csv\"), guess_max=100000)\n\nFor convenience, let’s make a couple of smaller subsets of the two tables. The shared key is the ID column subrecordid.\nI’ll keep all the rows from segments, but only the body and designs columns.\n\nsegments <-\nsegments_data %>%\n  select(subrecordid, body, designs)\n\nsegments\n\n# A tibble: 564,703 × 3\n   subrecordid body                designs                             \n   <chr>       <chr>               <chr>                               \n 1 cin77589    right arm           Man and woman|stars|dog             \n 2 cin77589    left arm            half|moon|stars|anchor|heart|diamond\n 3 cin77590    right arm           <NA>                                \n 4 cin77590    right hand          <NA>                                \n 5 cin77591    corner|left|eyebrow <NA>                                \n 6 cin77592    right arm           anchor                              \n 7 cin77592    <NA>                <NA>                                \n 8 cin77593    left hand           <NA>                                \n 9 cin77594    neck                <NA>                                \n10 cin77595    corner|right eye    <NA>                                \n# … with 564,693 more rows\n\n\nFrom descriptions, however, I’ll keep only those that contain tattoos, and the gender and year of birth columns.\n\ndescriptions <-\ndescriptions_data %>%\n  filter(hastattoo==\"y\") %>%\n  select(subrecordid, gender, born) \n\ndescriptions\n\n# A tibble: 75,448 × 3\n   subrecordid gender  born\n   <chr>       <chr>  <dbl>\n 1 cin77589    m       1814\n 2 cin77590    m       1820\n 3 cin77592    m       1820\n 4 cin77598    m       1824\n 5 cin77603    m       1792\n 6 cin77604    m       1814\n 7 cin77609    m       1830\n 8 cin77614    m       1815\n 9 cin77616    m       1815\n10 cin77619    m       1820\n# … with 75,438 more rows"
  },
  {
    "objectID": "post/2021-06-19-come-together-joining-data-tables/index.html#joining-with-dplyr",
    "href": "post/2021-06-19-come-together-joining-data-tables/index.html#joining-with-dplyr",
    "title": "Come TogetheR: Combining data tables in R with dplyr join verbs",
    "section": "Joining with dplyr",
    "text": "Joining with dplyr\nThe {dplyr} package provides a range of *_join verbs/functions for joining tables (which are quite similar to SQL joins, for anyone coming from SQL). In this post, I’ll look at four that I use most often.\nIn the following examples, you should think of segments as the left hand side and descriptions as the right hand side of the joins.\n(NB that dplyr documentation refers to the right hand side as “x” and the left as “y”. R error messages - eg if you try to join on a non-existent key - will refer to “LHS” and “RHS”.)\n\ninner_join and left_join\nThese two are examples of what the dplyr docs refer to as mutating joins, because they create new data tables.\nFirst up, inner_join(): this means that only rows in segments that have a matching subrecordid in descriptions are returned. The columns in descriptions are appended on the right. So I now have 5 columns but only 269205 rows, instead of the original 564703. Note how the information from descriptions is repeated where it has multiple matches in segments.\n\nsegments %>%\n  inner_join(descriptions, by=\"subrecordid\")\n\n# A tibble: 269,205 × 5\n   subrecordid body           designs                              gender  born\n   <chr>       <chr>          <chr>                                <chr>  <dbl>\n 1 cin77589    right arm      Man and woman|stars|dog              m       1814\n 2 cin77589    left arm       half|moon|stars|anchor|heart|diamond m       1814\n 3 cin77590    right arm      <NA>                                 m       1820\n 4 cin77590    right hand     <NA>                                 m       1820\n 5 cin77592    right arm      anchor                               m       1820\n 6 cin77592    <NA>           <NA>                                 m       1820\n 7 cin77598    left arm       <NA>                                 m       1824\n 8 cin77603    right|shoulder Crucifix                             m       1792\n 9 cin77603    right arm      man and woman                        m       1792\n10 cin77603    right arm      <NA>                                 m       1792\n# … with 269,195 more rows\n\n\nUsing left_join(), however, all the rows in segments are returned. Where there isn’t a matching subrecordid in descriptions, the right hand columns will be empty. It’s useful because sometimes you’ll want to keep the whole of the left-hand data after the join, for example to make calculations or checks based on the presence or absence of the right hand data.\n\nsegments %>%\n  left_join(descriptions, by=\"subrecordid\")\n\n# A tibble: 564,703 × 5\n   subrecordid body                designs                          gender  born\n   <chr>       <chr>               <chr>                            <chr>  <dbl>\n 1 cin77589    right arm           Man and woman|stars|dog          m       1814\n 2 cin77589    left arm            half|moon|stars|anchor|heart|di… m       1814\n 3 cin77590    right arm           <NA>                             m       1820\n 4 cin77590    right hand          <NA>                             m       1820\n 5 cin77591    corner|left|eyebrow <NA>                             <NA>      NA\n 6 cin77592    right arm           anchor                           m       1820\n 7 cin77592    <NA>                <NA>                             m       1820\n 8 cin77593    left hand           <NA>                             <NA>      NA\n 9 cin77594    neck                <NA>                             <NA>      NA\n10 cin77595    corner|right eye    <NA>                             <NA>      NA\n# … with 564,693 more rows\n\n\n\n\nanti_join and semi_join\nThese are called “filtering” joins. They don’t add the right-hand columns to the results. As the term suggests, they work in effect as filters, but instead of using criteria within the table you’re actually working on, the filtering behaviour is based on data in another table.\nI use anti_join() a lot: it returns the rows in the left-hand table that don’t have a match in the right-hand table. Apart from using it as a filter, it’s often really important when you’re checking and cleaning data - for example, for finding errors or inconsistencies in references that you need to use as keys.\n\nsegments %>%\n  anti_join(descriptions, by=\"subrecordid\")\n\n# A tibble: 295,498 × 3\n   subrecordid body                designs\n   <chr>       <chr>               <chr>  \n 1 cin77591    corner|left|eyebrow <NA>   \n 2 cin77593    left hand           <NA>   \n 3 cin77594    neck                <NA>   \n 4 cin77595    corner|right eye    <NA>   \n 5 cin77595    chin                <NA>   \n 6 cin77595    inside|right|ear    <NA>   \n 7 cin77596    top|forehead        <NA>   \n 8 cin77596    over|right eye      <NA>   \n 9 cin77597    left cheek          <NA>   \n10 cin77597    bone                <NA>   \n# … with 295,488 more rows\n\n\nThe second filtering join is semi_join(); it works like inner_join in that it returns only the left-hand rows that have a match on the right-hand side, but as with anti-join, it doesn’t append the right hand columns. You might wonder, what’s the point of that? But it’s faster and slightly easier if you simply want to use the join as a filter and don’t need any of the information in the right hand table.\n\nsegments %>%\n  semi_join(descriptions, by=\"subrecordid\")\n\n# A tibble: 269,205 × 3\n   subrecordid body           designs                             \n   <chr>       <chr>          <chr>                               \n 1 cin77589    right arm      Man and woman|stars|dog             \n 2 cin77589    left arm       half|moon|stars|anchor|heart|diamond\n 3 cin77590    right arm      <NA>                                \n 4 cin77590    right hand     <NA>                                \n 5 cin77592    right arm      anchor                              \n 6 cin77592    <NA>           <NA>                                \n 7 cin77598    left arm       <NA>                                \n 8 cin77603    right|shoulder Crucifix                            \n 9 cin77603    right arm      man and woman                       \n10 cin77603    right arm      <NA>                                \n# … with 269,195 more rows\n\n\n\n\ndo stuff inside the join function\nBecause of the way that tidyverse “pipes” work, you can manipulate the right-hand table inside the join. Let’s say I’d like to look at only descriptions in the Register of Habitual Criminals dataset: I can do the filter before applying the join.\n\nsegments %>%\n  inner_join(descriptions_data %>%\n               filter(dataset==\"rhc\") %>%\n               select(subrecordid, gender), by=\"subrecordid\")\n\n# A tibble: 450,109 × 4\n   subrecordid body           designs gender\n   <chr>       <chr>          <chr>   <chr> \n 1 rhc1        right|nose     <NA>    f     \n 2 rhc10       eyes           <NA>    m     \n 3 rhc100      back|head      <NA>    m     \n 4 rhc100      bottom|stomach <NA>    m     \n 5 rhc100      right|neck     <NA>    m     \n 6 rhc100      forehead       <NA>    m     \n 7 rhc100      right hand     <NA>    m     \n 8 rhc100      thigh          <NA>    m     \n 9 rhc100      nose           <NA>    m     \n10 rhc100      left|thigh     <NA>    m     \n# … with 450,099 more rows\n\n\n\n\nusing multiple variables as a key\nSometimes you need to join on more than one variable to ensure that your key is unique. In this case you have to combine the multiple keys in the by=“” argument into a vector using c() (c(\"key1\", \"key2\", \"etc\")).\n(It doesn’t actually make any difference in this example; it’s just a demonstration. But it will matter in the following example.)\n\nsegments_data %>%\n  select(subrecordid, life_id, body) %>%\n  inner_join(descriptions_data %>%\n               filter(hastattoo==\"y\") %>%\n               select(subrecordid, life_id, gender), \n             by=c(\"subrecordid\", \"life_id\"))\n\n# A tibble: 269,205 × 4\n   subrecordid life_id  body           gender\n   <chr>       <chr>    <chr>          <chr> \n 1 cin77589    cin77589 right arm      m     \n 2 cin77589    cin77589 left arm       m     \n 3 cin77590    cin77590 right arm      m     \n 4 cin77590    cin77590 right hand     m     \n 5 cin77592    cin77592 right arm      m     \n 6 cin77592    cin77592 <NA>           m     \n 7 cin77598    cin77598 left arm       m     \n 8 cin77603    cin77603 right|shoulder m     \n 9 cin77603    cin77603 right arm      m     \n10 cin77603    cin77603 right arm      m     \n# … with 269,195 more rows\n\n\n\n\njoining summarised data\nSo far all these joins have involved joining single data points using an ID column. But that’s not your only option. You might, for example, join already summarised data on a shared categorical key.\nLet’s get counts of gender for descriptions with tattoos, per dataset.\n\ndescriptions_gender_dataset_summary <-\ndescriptions_data %>%\n  filter(hastattoo==\"y\", dataset!=\"hcr\", gender %in% c(\"m\", \"f\")) %>%\n  count(dataset, gender, name=\"n_tattoos\")\n\ndescriptions_gender_dataset_summary\n\n# A tibble: 11 × 3\n   dataset gender n_tattoos\n   <chr>   <chr>      <int>\n 1 cin     m           2381\n 2 fas     f           1687\n 3 fas     m           9742\n 4 fas_pgo f            331\n 5 fas_pgo m           2321\n 6 mpr     f              3\n 7 mpr     m             65\n 8 pld     f             79\n 9 rhc     f           1535\n10 rhc     m          56396\n11 tlm     m            894\n\n\nI want to compare the numbers that have tattoos with all descriptions, and one way I can do this is with a join.\n\ndescriptions_gender_dataset_summary %>%\n  inner_join(\n    # counting inside the join\n    descriptions_data %>%\n      filter(dataset!=\"hcr\", gender %in% c(\"m\", \"f\")) %>%\n      count(dataset, gender, name=\"n_descriptions\"), \n    # join on both dataset *and* gender, or bad things will happen\n    by=c(\"dataset\", \"gender\")\n ) %>%\n  mutate(percent = n_tattoos/n_descriptions*100)\n\n# A tibble: 11 × 5\n   dataset gender n_tattoos n_descriptions percent\n   <chr>   <chr>      <int>          <int>   <dbl>\n 1 cin     m           2381           9719   24.5 \n 2 fas     f           1687          13677   12.3 \n 3 fas     m           9742          63151   15.4 \n 4 fas_pgo f            331           2347   14.1 \n 5 fas_pgo m           2321           8236   28.2 \n 6 mpr     f              3            270    1.11\n 7 mpr     m             65            643   10.1 \n 8 pld     f             79            882    8.96\n 9 rhc     f           1535          12969   11.8 \n10 rhc     m          56396         123005   45.8 \n11 tlm     m            894           6267   14.3"
  },
  {
    "objectID": "post/2021-06-19-come-together-joining-data-tables/index.html#now-what",
    "href": "post/2021-06-19-come-together-joining-data-tables/index.html#now-what",
    "title": "Come TogetheR: Combining data tables in R with dplyr join verbs",
    "section": "Now what?",
    "text": "Now what?\nAs in the last post, after joining I need to tidy designs onto separate lines…\n\nsegments_joined <-\nsegments %>%\n  inner_join(descriptions, by=\"subrecordid\") %>%\n  filter(!is.na(designs)) %>%\n  unnest_tokens(design, designs, token=\"regex\", pattern=\"\\\\|\")\n\nsegments_joined\n\n# A tibble: 196,978 × 5\n   subrecordid body      gender  born design       \n   <chr>       <chr>     <chr>  <dbl> <chr>        \n 1 cin77589    right arm m       1814 man and woman\n 2 cin77589    right arm m       1814 stars        \n 3 cin77589    right arm m       1814 dog          \n 4 cin77589    left arm  m       1814 half         \n 5 cin77589    left arm  m       1814 moon         \n 6 cin77589    left arm  m       1814 stars        \n 7 cin77589    left arm  m       1814 anchor       \n 8 cin77589    left arm  m       1814 heart        \n 9 cin77589    left arm  m       1814 diamond      \n10 cin77592    right arm m       1820 anchor       \n# … with 196,968 more rows\n\n\nNow I can compare gendered differences in the most popular tattoo designs. (With a few issues: “letters” is probably not a design.)\n\nsegments_joined %>%\n  count(design, gender, sort=TRUE) %>%\n  group_by(gender) %>%\n  top_n(10, n) %>%\n  ungroup() %>%\n  mutate(design = reorder_within(design, n, gender)) %>%\n  ggplot(aes(x=design, y=n, fill=gender)) +\n  geom_col(show.legend = FALSE) +\n  coord_flip() +\n  scale_x_reordered() +\n  scale_fill_tableau() +\n  facet_wrap(~gender, scales = \"free\") +\n  labs(y=\"count\", x=NULL, title=\"Top ten tattoo designs by gender\")\n\n\n\n\nAnd there are some striking variations in the proportions of male/female descriptions that have tattoos between different datasets.\n\ndescriptions_gender_dataset_summary %>%\n  inner_join(\n    descriptions_data %>%\n      filter(dataset!=\"hcr\", gender %in% c(\"m\", \"f\")) %>%\n      count(dataset, gender, name=\"n_descriptions\"), \n    by=c(\"dataset\", \"gender\")\n ) %>%\n  mutate(percent = n_tattoos/n_descriptions) %>%\n  mutate(dataset = case_when(\n    dataset %in% c(\"pld\", \"tlm\") ~ \"pld\",\n    TRUE ~ dataset\n  )) %>%\n  ggplot(aes(x=dataset, y=percent, fill=gender)) +\n  geom_col(position = position_dodge2(preserve = \"single\", padding = 0)) +\n  scale_y_continuous(labels = percent_format()) +\n  scale_fill_tableau() +\n  labs(y=\"% with tattoos\")"
  },
  {
    "objectID": "post/2021-06-19-come-together-joining-data-tables/index.html#resources",
    "href": "post/2021-06-19-come-together-joining-data-tables/index.html#resources",
    "title": "Come TogetheR: Combining data tables in R with dplyr join verbs",
    "section": "Resources",
    "text": "Resources\nA beginner’s guide to joining data.\nRelational data - an essential detailed introduction to {dplyr} joins, by Hadley Wickham.\nSTAT 545: Join two tables for more examples and exercises.\n\nextending dplyr joins\nWhen using {dplyr} joins, your key has to be an exact match. But sometimes you’ll find that what you want is a join function that allows for inexact matches. The fuzzyjoin package does just that, but uses the same basic format as the joins above. It includes, for example, joins on numeric values, similar strings, regular expressions, and overlapping intervals.\nAnother more specialised join package is funneljoin which may be useful where you want to analyse a sequence of events (eg, “maybe you’re interested in finding the people who visit a page and then register”). [NB: I haven’t tried this one yet.]"
  },
  {
    "objectID": "post/2018-11-03-introduction/index.html#the-project",
    "href": "post/2018-11-03-introduction/index.html#the-project",
    "title": "Introducing the Tattoos Project",
    "section": "The project",
    "text": "The project\nThis website accompanies the British Academy funded project Criminal Tattoos.\n\nThe remarkable increase in tattooing among convicts in the nineteenth century is poorly understood. It is unclear why convicts marked their bodies in ways which facilitated official surveillance, nor do we understand the complex mixture of sentiments expressed. Building on existing, but limited, case studies, this project will analyse tattoos on 60,700 convicts in Britain and Australia from 1788 to 1925, examining descriptions of tattoos alongside evidence of convicts’ personal backgrounds. While this evidence is available within the Digital Panopticon web resource, this topic is currently impossible to research because 1) information about tattoos is often cryptic and enmeshed within broader descriptive fields, and 2) existing search and visualisation facilities do not enable the data to be usefully interrogated and synthesised. This project will develop new methods of data extraction and visualisation in order to better understand the meanings embedded within this and other rich bodies of fragmentary textual evidence.\n\nThe project has two main components:\n\nData extraction and classification\nThe physical description fields in the datasets consist of undifferentiated and fragmentary language which can include various physical attributes (eg heights, scars, disabilities) in addition to tattoos. Descriptions of tattoos are also varied and include a variety of names, initials, dates, emotions, objects and symbols. These scraps of descriptive language need to be identified, delineated and classified, but the datasets are too large in most cases for it to be feasible to mark them up manually. Instead, the project will build on and extend automated techniques developed for the Digital Panopticon. The Digital Humanities Institute, Sheffield, will be primarily responsible for the development work.\n\n\nData analysis and visualisation\nWhich is where this blog comes in! I’ll be using R to experiment with data analysis and visualisation techniques in order to explore some of the project’s research questions. In addition to tattoos, we’ll have significant amounts of biographical information for many individuals, including gender, age, occupation, religion, type of crime, previous convictions, and punishment and we’ll explore ways to use visualisation to summarise and analyse this evidence, in order to identify the specific contexts in which tattooing, and particular types of tattoos, were used.\nIn the process I hope to offer methods that will be transferable to analyse other types of complex and fragmentary textual data found in many historical (and contemporary) sources.\nResearch questions include:\n\nWhy, over the course of the nineteenth century, did convicts increasingly use their bodies as sites for recording their life events and expressing their identity and sentiments, despite the fact the state collected evidence of their tattoos for surveillance purposes?\nWhich convicts, and from which social contexts, were most likely to have tattoos? How does tattooing vary by gender, age, occupation, religion and place of origin? How did these patterns change over the course of the nineteenth century?\nAre there any significant differences between the tattoos of convicts who were transported to Australia and those who were imprisoned in Britain? Were recidivists more likely to have tattoos, and how did convicts chart their penal experiences?\nWhat light does the practice of tattooing shed on changing attitudes towards the body in the nineteenth century?"
  },
  {
    "objectID": "post/2018-11-03-introduction/index.html#the-datasets",
    "href": "post/2018-11-03-introduction/index.html#the-datasets",
    "title": "Introducing the Tattoos Project",
    "section": "The datasets",
    "text": "The datasets\nThe project focuses on evidence of tattooing found in six major datasets in the Digital Panopticon. The broad chronological and geographical range allows the project to analyse change over time and to compare tattoos on transported and imprisoned convicts.\nThe counts of individuals with tattoos are estimates. The data is based on textual descriptions of tattoos, not images. (Very occasionally officials added rough sketches of tattoos, but this seems to be uncommon.)\n\n\n\n\n\n\n\n\ndataset\nlocation\nstart\nend\nindividuals\n\n\n\n\nCriminal Registers\nLondon\n1791\n1801\n25\n\n\nFounders and Survivors\nTasmania\n1803\n1853\n9000\n\n\nMillbank Prison Register\nLondon\n1816\n1826\n120\n\n\nConvict Indents\nWestern Australia\n1850\n1868\n1000\n\n\nConvict Licences\nLondon\n1853\n1887\n550\n\n\nRegisters of Habitual Criminals\nEng+Wales\n1881\n1925\n50000\n\n\n\n\n\nSome of the datasets focus on London criminals: the Criminal registers listed only London/Middlesex prisoners, and the Digital Panopticon transcribed in detail only London prisoners in the Millbank prison register and Convict licences). The other datasets have national coverage (Founders and Survivors, WA convict indents, Registers of habitual criminals)."
  },
  {
    "objectID": "post/2018-11-03-introduction/index.html#the-descriptions",
    "href": "post/2018-11-03-introduction/index.html#the-descriptions",
    "title": "Introducing the Tattoos Project",
    "section": "The descriptions",
    "text": "The descriptions\nI’ll take a closer look at the data in later posts, but here are a few examples of descriptions containing tattoos, to show why the data extraction part of the project is such a challenge.\n\nCriminal registers\nThe number of tattooed individuals in this dataset is very small and probably not suitable for quantitative analysis, but 18th-century evidence of tattoos in Britain is rare so this may still provide useful context.\n\n\n\n\n\n\n\n\ndescription\n\n\n\n\nAged 19. 5F/4I Sallow brown hair grey eyes Monaghar Ireland a Marine has an Anchor marked on left arm his right\n\n\n25 Yrs. 5F/8I. Fresh Complex. brown hair grey eyes Kelse Scotland a Mariner served his apprenticeship from Shields in Ye. So Sea & Greenland. Trade & in the Shunderer was at has a woman & a Square & Compass marked on his left arm & on or cast .on the Cross\n\n\nAged 20. 5F. 5I. Fair Complex brown hair dark eyes Ireland in his right arm is marked emblems of Musenry, on is left arm Arist or certified, with the Mitials of new name Marner\n\n\nAged 21. 5F. 5I. Fair Complex brown hair dark eyes Cork Ireland on his left arm is marked Mermaid wish W. I. & W. M. I. M. on to wright arm taken in the Manly Captn. Adams of Pool.\n\n\n\n\n\n\n\nFounders and Survivors\nThese were recorded after arrival in Tasmania and at least some were acquired after leaving Britain, so it’ll be interesting to compare them with the data for prisoners in Britain.\n\n\n\n\n\n\n\n\n\n\n\ndescription\n\n\n\n\nJR’ ‘MAH’ above elbow joint right arm. Ring on middle finger right hand. Large scar right hand near little finger. ‘SH’ on right arm.\n\n\nT.F.R.H. rt arm S.H left arm - Stout made -\n\n\nLost some front Teeth Lower Jaw 6 Blue dots on left Hand\n\n\n<[X: H]> TT. A.N. H. WC LL on Rt Shoulder\n\n\n3 blue dots on left Hand\n\n\n\n\n\n\n\nRegisters of Habitual Criminals\nIndividuals could appear on numerous occasions in the registers. This makes the data more complex, but offers the potential to trace evolving personal biographies rather than snapshots at a single moment in time.\n\n\n\n\n\n\n\n\n\n\n\nmarks\n\n\n\n\nSailor and flag right arm, mole right shoulder\n\n\nRose, thistle and shamrock on left wrist, ship on right arm\n\n\nBlue dot right arm, mole right breast, birth-mark top of left foot, lost all front upper teeth\n\n\nRing third right finger, dot back of each hand, cross-flags left arm, sailor right arm, moles on back and neck\n\n\nT. and three indistinct marks right arm, scars on chest, left eye, left wrist, back, back of head and left of head"
  },
  {
    "objectID": "post/2018-11-03-introduction/index.html#code-and-data",
    "href": "post/2018-11-03-introduction/index.html#code-and-data",
    "title": "Introducing the Tattoos Project",
    "section": "Code and data",
    "text": "Code and data\nI’ll be using R, a programming language particularly geared towards statistical analysis and visualisation, throughout this blogging project.\nMore specifically, my R workflow has these key components:\n\nRStudio, an “integrated development environment” (IDE) for R (free open source software, multi-platform)\nThe Tidyverse, “an opinionated collection of R packages designed for data science” (personally speaking, this was the single most important thing that transformed R into a language I could actually understand and use)\nMarkdown and RMarkdown for writing\nQuarto and Github Pages for publishing\n\nThis enables me to do most of what I need for the project - data wrangling and tidying, exploratory analysis, data modelling and visualisation, blogging - in one place, so that (hopefully…) everything I do will be easily re-usable, either to test and reproduce my own results or as examples that can be adapted for other data and research.\nThere will be a fair bit of R code in most blog posts; this will be familiar to any readers who follow data science blogs, but less so to many historians. One of the goals of this blog is to show how R can be of practical use for working with large, complex historical datasets, right through the research process from data management to writing and publication. So, with this in mind, I’m also compiling a list of resources, which will be regularly updated during the project, focusing on resources (tutorials, guides, packages, etc) that I’ve actually used and found helpful.\n(It doesn’t have to be R; Python, for example, can be used with the same kind of workflow. I think R is stronger specifically on statistical analysis and visualisation options, especially for data that doesn’t need a lot of work to make it ready for use, whereas Python would be better if I needed to do more heavyweight data processing and development.)\nAll R code and data will be made available for re-use at the project’s Github repository. Some of the data being used by the project is already publicly available from the University of Sheffield data repository and other datasets will be added there or on Github during the course of this project. Datasets will be Creative Commons-licensed (or similar) for re-use unless otherwise stated, but the exact license terms are likely to vary."
  },
  {
    "objectID": "post/2018-11-03-introduction/index.html#whats-next",
    "href": "post/2018-11-03-introduction/index.html#whats-next",
    "title": "Introducing the Tattoos Project",
    "section": "What’s next?",
    "text": "What’s next?\nThe initial phase of the project will be focusing on data cleaning and preparation for the process of extraction and classification. My first posts here will take a closer look at the descriptions data. I’ll be comparing datasets and using some basic textmining, exploring how the descriptions were originally recorded, the range of information included, and the variability of the language used.\nIn later months, I’ll experiment with ways of mining and visualising the tattoos corpus, and using the linked life archives data to analyse relationships between tattooing and convicts’ biographical and social characteristics."
  },
  {
    "objectID": "post/2019-05-21-tattoos-hackathon-16-april-2019/index.html",
    "href": "post/2019-05-21-tattoos-hackathon-16-april-2019/index.html",
    "title": "Tattoos Hackathon, 16 April 2019",
    "section": "",
    "text": "For the project’s data hackathon last month, I put together a few very exploratory slides. I’m currently working on more ideas, but I thought I’d put these up to whet a few appetites.\nThe data itself is still very much work in progress, so on this occasion I’m not going to share the dataset; sorry, you’ll just have to wait a bit longer! And these could change quite a bit by the time the data is finalised (so they really should not be treated as findings that could be cited in a publication!).\nI think of the tattoos data as being more like, say, Twitter data rather than corpora of ‘big’ texts like novels. The vocabulary is relatively limited; descriptions are usually not full grammatical sentences. They contain quite small amounts of text. Tattoos themselves, in this analogy, are comparable to hashtags. And finally, there is a lot of associated metadata beyond the text itself - including who, where, and when, and links between the descriptions.\nTwo main challenges:\n\nanalysing the language itself - collocations and correlations\nfinding patterns with other variables eg gender, religion, change over time, etc"
  },
  {
    "objectID": "post/2019-05-21-tattoos-hackathon-16-april-2019/index.html#designs-word-correlations-selected-words",
    "href": "post/2019-05-21-tattoos-hackathon-16-april-2019/index.html#designs-word-correlations-selected-words",
    "title": "Tattoos Hackathon, 16 April 2019",
    "section": "Designs: word correlations (selected words)",
    "text": "Designs: word correlations (selected words)\nFor several of these, I’ve borrowed ideas and code from the excellent Text Mining with R book.\nHere, I compare the top co-occurring words for four high-frequency words in tattoo designs, using pairwise correlation. This means “how often they appear together relative to how often they appear separately” (so you don’t just get the most frequently occurring pairs at the top of the list)."
  },
  {
    "objectID": "post/2019-05-21-tattoos-hackathon-16-april-2019/index.html#designs-word-correlations",
    "href": "post/2019-05-21-tattoos-hackathon-16-april-2019/index.html#designs-word-correlations",
    "title": "Tattoos Hackathon, 16 April 2019",
    "section": "Designs: word correlations",
    "text": "Designs: word correlations\nThe same method is used to measure correlations between all words in designs so they can be visualised as a network and find out which designs/words are most likely to co-occur.\nThis shows only correlations above a certain threshold, but I forgot (ahem) to filter out very low frequency designs, so it includes some words that only occur once or twice in the whole dataset. The darker the lines (edges) between words, the stronger the association."
  },
  {
    "objectID": "post/2019-05-21-tattoos-hackathon-16-april-2019/index.html#subjects-correlation-plot",
    "href": "post/2019-05-21-tattoos-hackathon-16-april-2019/index.html#subjects-correlation-plot",
    "title": "Tattoos Hackathon, 16 April 2019",
    "section": "Subjects: correlation plot",
    "text": "Subjects: correlation plot\n“Subjects” are classifications being added to tattoos designs by the project team. The process is not complete and is of course very subjective and quite selective (reflecting research interests). So this graph is even more provisional than the rest (!), and I don’t think it’s particularly effective. But I wanted to try one out and see!\nInterpreting the graph: Positive correlations (subjects appear together) are displayed in blue and negative correlations in red. Colour intensity and the size of the square are proportional to the correlation coefficients. A positive correlation of 1 = the subjects always appear together; a negative correlation of -1 = never together; 0 = equally likely to be together or apart."
  },
  {
    "objectID": "post/2019-05-21-tattoos-hackathon-16-april-2019/index.html#designs-comparing-word-use-by-punishment",
    "href": "post/2019-05-21-tattoos-hackathon-16-april-2019/index.html#designs-comparing-word-use-by-punishment",
    "title": "Tattoos Hackathon, 16 April 2019",
    "section": "Designs: comparing word use by punishment",
    "text": "Designs: comparing word use by punishment\nThis is probably my favourite new type of dataviz for comparing paired categories of words.\nWe go back to designs but now add another variable, a comparison of tattoo designs for transported v imprisoned convicts (which also has strong chronological dimension). First calculate word frequencies and divide the corpus into “transported” and “imprisoned”.\nInterpretation:\n\nfocus on the red line: words above this are associated more with transportation than with imprisonment; words below the red line are associated more with imprisonment\nthe further from the red line, the stronger the association\nwords towards the top right hand corner are higher frequency, towards the bottom left corner, lower frequency.\n\nNB a limitation is that the graph will only show words that are in both transportation and imprisonment. This is not an issue when your corpus has very large numbers of unique tokens, but I think it makes it (sadly) less effective in this case.\n(If it’s too small to see properly in your browser, right click on it and select “View Image” to see it at full size.)"
  },
  {
    "objectID": "post/2021-05-15-tidying-tattoos/index.html",
    "href": "post/2021-05-15-tidying-tattoos/index.html",
    "title": "Tidying Tattoos: Handling missing data and non-tidy columns",
    "section": "",
    "text": "“Tidy” data describes data that conforms to three rules:\n\nEach variable must have its own column.\nEach observation must have its own row.\nEach value must have its own cell.\n\nData usually needs to be in a tidy format to work with R Tidyverse tools. But it isn’t necessarily the best format for data entry or storage, and very few real world datasets are tidy. So it’s almost always necessary to do some tidying as well as cleaning up more general messiness before being able to analyse data, and the Criminal Tattoos data is no exception. This post introduces just a couple of very common issues:\n\ncleaning: missing data, which can be encoded in varying ways\ntidying: multiple values in a single cell\n\nI think this is also a good introduction to the fluidity of working with data in software like R. The same data can be easily reshaped in many ways, depending on the task in hand, and be manipulated several times in the course of the same analysis."
  },
  {
    "objectID": "post/2021-05-15-tidying-tattoos/index.html#the-data",
    "href": "post/2021-05-15-tidying-tattoos/index.html#the-data",
    "title": "Tidying Tattoos: Handling missing data and non-tidy columns",
    "section": "The data",
    "text": "The data\nLoad the Tidyverse packages and the descriptions data file. (For more on both of these, see this introductory post.)\n\nlibrary(tidyverse)\n\ndescriptions_data <- \n  read_csv(here::here(\"_data\", \"convict_descriptions.2020-12-17.csv\"), guess_max = 100000)\n\nI don’t want all the stuff in the file, so I’ll slim it down a bit, to keep only descriptions that contain tattoos and the columns that I’ll be working with here.\n\ntattoo_descriptions <-\n  descriptions_data %>%\n  filter(hastattoo==\"y\") %>%\n  select(subrecordid, descyear, born, gender, designs, digest)"
  },
  {
    "objectID": "post/2021-05-15-tidying-tattoos/index.html#missing-data",
    "href": "post/2021-05-15-tidying-tattoos/index.html#missing-data",
    "title": "Tidying Tattoos: Handling missing data and non-tidy columns",
    "section": "Missing data",
    "text": "Missing data\nSummarising a variable often immediately highlights problems. In this case, missing description years (as well as birth years) are encoded as 0.\n\ntattoo_descriptions %>%\n  count(descyear)\n\n# A tibble: 125 × 2\n   descyear     n\n      <dbl> <int>\n 1        0   279\n 2     1793     1\n 3     1796     1\n 4     1797    11\n 5     1798     1\n 6     1801     1\n 7     1804     1\n 8     1806     2\n 9     1808     2\n10     1809     1\n# … with 115 more rows\n\n\nR doesn’t know that 0 means “missing”; it just treats it as a number.\n\ntattoo_descriptions %>%\n  count(descyear) %>%\n  ggplot(aes(x=descyear, y=n)) +\n  geom_line()\n\n\n\n\nI could just filter out 0s in a plot like this, but it’s better to convert them to “NA” from the start so R will handle them properly. There are several ways to do this.\n\na simple case\nIf you want to convert every 0 in your data to NA, na_if() is used to be an easy and convenient option. (A recent software update outlawed this use of na_if(). Apparently it was unintended and “accidental”.)\n\ntattoo_descriptions %>%\n  select(descyear, born) %>%\n  filter(descyear==0) %>% \n  # convert 0s in both descyear and born to NA\n  mutate(descyear = na_if(descyear, 0), born=na_if(born, 0))\n\n# A tibble: 279 × 2\n   descyear  born\n      <dbl> <dbl>\n 1       NA    NA\n 2       NA    NA\n 3       NA    NA\n 4       NA    NA\n 5       NA    NA\n 6       NA    NA\n 7       NA  1797\n 8       NA    NA\n 9       NA    NA\n10       NA    NA\n# … with 269 more rows\n\n  # na_if(0)  # this is no longer permitted \n  # you could do this instead\n  # mutate(across(everything(), ~na_if(., 0)))\n\n\n\nmore complex cases\nA smarter option is replace_with_na() (from the {naniar} package). With this, you can specify which columns need attention, and list several possible values that might need conversion to NA (common variants might include -99 or “unknown”).\n\nlibrary(naniar)\n\n\ntattoo_descriptions %>%\n  select(descyear, born, gender) %>%\n  filter(descyear==0) %>%\n  # replace only 0s in descyear with NA\n  replace_with_na(replace=list(descyear=0))\n\n# A tibble: 279 × 3\n   descyear  born gender\n      <dbl> <dbl> <chr> \n 1       NA     0 m     \n 2       NA     0 m     \n 3       NA     0 m     \n 4       NA     0 m     \n 5       NA     0 m     \n 6       NA     0 m     \n 7       NA  1797 m     \n 8       NA     0 m     \n 9       NA     0 m     \n10       NA     0 m     \n# … with 269 more rows\n\n\nWhat about gender? For some reason there are both “u” for unknown and NA in the data. (Admittedly, there are only two of them so I’d be inclined to just drop them in this case…)\n\ntattoo_descriptions %>%\n  count(gender)\n\n# A tibble: 4 × 2\n  gender     n\n  <chr>  <int>\n1 f       3635\n2 m      71811\n3 u          1\n4 <NA>       1\n\n\nI can fix several missing data issues in the same line of code.\n\ntattoo_descriptions %>%\n  select(descyear, born, gender) %>%\n  filter(gender==\"u\" | is.na(gender)) %>%\n  # replace 0s in descyear and born and \"u\" in gender with NA\n  replace_with_na(replace=list(descyear=0, born=0, gender=\"u\"))\n\n# A tibble: 2 × 3\n  descyear  born gender\n     <dbl> <dbl> <chr> \n1     1881    NA <NA>  \n2     1881  1837 <NA>  \n\n\nAfter the 0s have been replaced with NAs, the line chart drops the missing years automatically (I can suppress the warning message, if that’s the behaviour I want, or investigate further if it isn’t).\n\ntattoo_descriptions %>%\n  replace_with_na(replace=list(descyear=0)) %>%\n  count(descyear) %>%\n  ggplot(aes(x=descyear, y=n)) +\n  geom_line()"
  },
  {
    "objectID": "post/2021-05-15-tidying-tattoos/index.html#multiple-values-in-one-cell",
    "href": "post/2021-05-15-tidying-tattoos/index.html#multiple-values-in-one-cell",
    "title": "Tidying Tattoos: Handling missing data and non-tidy columns",
    "section": "Multiple values in one cell",
    "text": "Multiple values in one cell\n\na simple case\nThe designs column contains all the tattoo designs identified in a description, separated with a “pipe” | symbol. This makes sense as a concise format for storing the data, but it’s not at all tidy or easy to work with.\n\ntattoo_descriptions %>%\n  filter(!is.na(designs)) %>%\n  select(subrecordid, designs)\n\n# A tibble: 64,098 × 2\n   subrecordid designs                                             \n   <chr>       <chr>                                               \n 1 cin77589    anchor|dog|moon|man and woman|diamond|half|sun|heart\n 2 cin77592    anchor                                              \n 3 cin77603    man and woman|crucifix|mermaid                      \n 4 cin77604    dot                                                 \n 5 cin77609    dot|ring                                            \n 6 cin77616    sun moon and stars                                  \n 7 cin77619    woman|flower pot                                    \n 8 cin77622    figure|woman|shamrock|thistle                       \n 9 cin77623    crown                                               \n10 cin77626    ship|anchor|crown|thistle|ring|rose|mermaid         \n# … with 64,088 more rows\n\n\nAgain, I have more than one option for this.\nOne is a two-step process. First, str_split() splits up the string into pieces on each | symbol, putting them in a “list-column”.\n\ntattoo_descriptions %>%\n  select(subrecordid, designs) %>%\n  filter(!is.na(designs)) %>%\n  mutate(design = str_split(designs, \"\\\\|\")) \n\n# A tibble: 64,098 × 3\n   subrecordid designs                                              design   \n   <chr>       <chr>                                                <list>   \n 1 cin77589    anchor|dog|moon|man and woman|diamond|half|sun|heart <chr [8]>\n 2 cin77592    anchor                                               <chr [1]>\n 3 cin77603    man and woman|crucifix|mermaid                       <chr [3]>\n 4 cin77604    dot                                                  <chr [1]>\n 5 cin77609    dot|ring                                             <chr [2]>\n 6 cin77616    sun moon and stars                                   <chr [1]>\n 7 cin77619    woman|flower pot                                     <chr [2]>\n 8 cin77622    figure|woman|shamrock|thistle                        <chr [4]>\n 9 cin77623    crown                                                <chr [1]>\n10 cin77626    ship|anchor|crown|thistle|ring|rose|mermaid          <chr [7]>\n# … with 64,088 more rows\n\n\nThen unnest() is used to unpack each element of the list onto its own line.\n\ntattoo_descriptions_unnest <-\ntattoo_descriptions %>%\n  filter(!is.na(designs)) %>%\n  mutate(design = str_split(designs, \"\\\\|\")) %>%\n  unnest(design)\n\ntattoo_descriptions_unnest %>%\n  select(subrecordid, design) \n\n# A tibble: 176,777 × 2\n   subrecordid design       \n   <chr>       <chr>        \n 1 cin77589    anchor       \n 2 cin77589    dog          \n 3 cin77589    moon         \n 4 cin77589    man and woman\n 5 cin77589    diamond      \n 6 cin77589    half         \n 7 cin77589    sun          \n 8 cin77589    heart        \n 9 cin77592    anchor       \n10 cin77603    man and woman\n# … with 176,767 more rows\n\n\nBut in fact I find it easier to use unnest_tokens() ({tidytext} package) to do this kind of task. It has more options for more complex cases, can be done in a single step, and is quicker.\n\nlibrary(tidytext)\n\n\ntattoo_descriptions_unnest_tokens <-\ntattoo_descriptions %>%\n  filter(!is.na(designs)) %>%\n  unnest_tokens(design, designs, token=\"regex\", pattern=\"\\\\|\", to_lower = FALSE)\n\ntattoo_descriptions_unnest_tokens %>%\n  select(subrecordid, design) \n\n# A tibble: 176,777 × 2\n   subrecordid design       \n   <chr>       <chr>        \n 1 cin77589    anchor       \n 2 cin77589    dog          \n 3 cin77589    moon         \n 4 cin77589    man and woman\n 5 cin77589    diamond      \n 6 cin77589    half         \n 7 cin77589    sun          \n 8 cin77589    heart        \n 9 cin77592    anchor       \n10 cin77603    man and woman\n# … with 176,767 more rows\n\n\n\n\nmore complex cases\nThe digest column is a considerably more complicated case. It contains what we called “body chunks” for each description - each body location identified as having at least one tattoo, followed by the list of tattoo terms. The format is [body part : list|of|terms], with chunks separated by a space.\n\ntattoo_descriptions %>%\n  select(digest) \n\n# A tibble: 75,448 × 1\n   digest                                                                       \n   <chr>                                                                        \n 1 [right arm : man and woman|sun|dog|ST|1838]  [left arm : half|moon|sun|ancho…\n 2 [right arm : CPEP]  [right hand : JP]                                        \n 3 [right arm : anchor|LARK]  [ : EM]                                           \n 4 [left arm : TH]                                                              \n 5 [right|shoulder : crucifix]  [right arm : man and woman]  [left arm : mermai…\n 6 [right hanging body specifier|hand : dot|dot]                                \n 7 [left hand : dot|ring]                                                       \n 8 [left arm : MB]                                                              \n 9 [left arm : sun moon and stars]                                              \n10 [left hand : flower pot]  [right following body specifier : woman]           \n# … with 75,438 more rows\n\n\nThree distinct steps are needed:\n\nput each chunk on its own line\nseparate body part and tattoos\nput each tattoo on its own line\n\nFor the first step, I’ll use unnest_tokens again, followed by str_remove_all() to get rid of the square brackets.\n(This needs a more advanced regex than the previous example; if you want to know more about how the regex works, try pasting the expression (?=\\[[^\\]]+\\]) * into here.)\n\ntattoo_chunks_unnest_tokens <-\ntattoo_descriptions %>%\n  select(subrecordid, digest) %>%\n  unnest_tokens(chunk, digest, token=\"regex\", pattern=\"(?=\\\\[[^\\\\]]+\\\\]) *\", to_lower = FALSE) %>%\n  mutate(chunk = str_remove_all(chunk, \"\\\\[|\\\\]\"))\n\ntattoo_chunks_unnest_tokens\n\n# A tibble: 143,609 × 2\n   subrecordid chunk                                              \n   <chr>       <chr>                                              \n 1 cin77589    \"right arm : man and woman|sun|dog|ST|1838  \"      \n 2 cin77589    \"left arm : half|moon|sun|anchor|heart|diamond|IMB\"\n 3 cin77590    \"right arm : CPEP  \"                               \n 4 cin77590    \"right hand : JP\"                                  \n 5 cin77592    \"right arm : anchor|LARK  \"                        \n 6 cin77592    \" : EM\"                                            \n 7 cin77598    \"left arm : TH\"                                    \n 8 cin77603    \"right|shoulder : crucifix  \"                      \n 9 cin77603    \"right arm : man and woman  \"                      \n10 cin77603    \"left arm : mermaid\"                               \n# … with 143,599 more rows\n\n\nStep two, splitting body part and tattoo terms into separate columns, uses the separate() function.\n\ntattoo_chunks_unnest_tokens_separated <-\ntattoo_chunks_unnest_tokens %>%\n  separate(chunk, into=c(\"body\", \"tattoos\"), sep=\" *: *\")\n\ntattoo_chunks_unnest_tokens_separated\n\n# A tibble: 143,609 × 3\n   subrecordid body             tattoos                                 \n   <chr>       <chr>            <chr>                                   \n 1 cin77589    \"right arm\"      \"man and woman|sun|dog|ST|1838  \"       \n 2 cin77589    \"left arm\"       \"half|moon|sun|anchor|heart|diamond|IMB\"\n 3 cin77590    \"right arm\"      \"CPEP  \"                                \n 4 cin77590    \"right hand\"     \"JP\"                                    \n 5 cin77592    \"right arm\"      \"anchor|LARK  \"                         \n 6 cin77592    \"\"               \"EM\"                                    \n 7 cin77598    \"left arm\"       \"TH\"                                    \n 8 cin77603    \"right|shoulder\" \"crucifix  \"                            \n 9 cin77603    \"right arm\"      \"man and woman  \"                       \n10 cin77603    \"left arm\"       \"mermaid\"                               \n# … with 143,599 more rows\n\n\nFinally, to put each tattoo on its own line, I repeat the earlier step with unnest_tokens. The new output is a bit different from the first case because the digest includes everything identified as a tattoo, not just pictorial designs.\n\ntattoo_chunks_tattoos_unnest_tokens <-\ntattoo_chunks_unnest_tokens_separated %>%\n  unnest_tokens(tattoo, tattoos, token=\"regex\", pattern=\"\\\\|\", to_lower = FALSE)\n\ntattoo_chunks_tattoos_unnest_tokens\n\n# A tibble: 343,417 × 3\n   subrecordid body      tattoo         \n   <chr>       <chr>     <chr>          \n 1 cin77589    right arm \"man and woman\"\n 2 cin77589    right arm \"sun\"          \n 3 cin77589    right arm \"dog\"          \n 4 cin77589    right arm \"ST\"           \n 5 cin77589    right arm \"1838  \"       \n 6 cin77589    left arm  \"half\"         \n 7 cin77589    left arm  \"moon\"         \n 8 cin77589    left arm  \"sun\"          \n 9 cin77589    left arm  \"anchor\"       \n10 cin77589    left arm  \"heart\"        \n# … with 343,407 more rows"
  },
  {
    "objectID": "post/2021-05-15-tidying-tattoos/index.html#now-what",
    "href": "post/2021-05-15-tidying-tattoos/index.html#now-what",
    "title": "Tidying Tattoos: Handling missing data and non-tidy columns",
    "section": "Now what?",
    "text": "Now what?\nNow I can have a lot more fun!\n\ntattoo_descriptions_unnest_tokens %>%\n  count(design, sort=TRUE) %>%\n  head(10) %>%\n  ggplot(aes(x=fct_reorder(design, n), y=n)) +\n  geom_col() +\n  coord_flip() +\n  labs(y=\"count\", x=NULL, title=\"Top ten tattoo designs\")\n\n\n\n\nWhich are the most popular body locations for tattoos? This needs more cleaning, but you get the gist.\n\ntattoo_chunks_unnest_tokens_separated %>%\n  mutate(body = str_replace_all(body, \"\\\\|\", \" \")) %>%\n  count(body, sort = TRUE) %>%\n  head(10) %>%\n  ggplot(aes(x=fct_reorder(body, n), y=n)) +\n  geom_col() +\n  coord_flip() +\n  labs(y=\"count\", x=NULL, title=\"Top ten tattoo locations\")\n\n\n\n\nAnd here’s one I cleaned up earlier…"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Nineteenth-Century Criminal Tattoos",
    "section": "",
    "text": "Tattooing has a long history, but the practice increased significantly in Britain and Australia in the nineteenth century, when a growing number of criminal convicts acquired tattoos. Their many meanings include expressions of love, hope, pain, defiance, fraternity, and religious commitment, and aspirations to be fashionable. As a largely voluntary practice, tattooing provides valuable evidence of non-elite voices which are otherwise difficult to locate in the historical record.\nWhile tattooing has been the subject of a few studies, particularly of convicts transported to Tasmania (1802-53) and imprisoned in Ireland (1895-99), most research to date has been based on limited data and there is much that we still do not understand about the practice. While tattoos can be interpreted as expressions of convicts’ individuality and aspirations, official practices of recording tattoos when documenting their physical characteristics can be seen as a form of state control. It is unclear why convicts engaged in a practice which facilitated such control, and whether the increasing use of tattooing signalled the growth of a defiant criminal subculture, or of more inclusive cultural aspirations.\nThe Digital Panopticon, launched in September 2017, brings together fifty existing datasets of criminal justice records for reuse, linking convict records together to enable life course analysis of over 250,000 convicts. There are approximately 60,000 descriptions of tattooed convicts in the Digital Panopticon, but the information is not currently systematically accessible, as it is intermixed with other physical details, such as eye colour, scars, bodily shape and physical infirmities, often using extensive abbreviations and inconsistent punctuation:\n\nCrucifix above elbow Joint rt arm deep dimple on chin Scar near outer corner rt eye Moon & 7 stars JW mermaid anchor JC MD JD TD & Cannon (Prop) inside rt arm (James Rees, transported to Tasmania in 1826)\n\nIn addition to the challenge of extracting relevant information concerning tattoos from the highly varied physical description fields in the Digital Panopticon, a second technical challenge exists in coping with the complexity of the multiple variables available, and in summarising such voluminous and diverse data.\nVia Digital Panopticon’s ‘life archives’, information about tattoos can be linked to a large amount of other evidence about the convict, including their gender, age, occupation, religion, place of origin, type of crime committed, previous convictions, and punishment. The Digital Panopticon has experimented with a number of visualisations to summarise this data and detect patterns, notably Sankey diagrams, pie charts, and specially developed ‘life charts’, but these formats are inadequate to the task of displaying complex multivariate data about convicts and their tattoos. The Tattoos project will use this blog to explore and experiment with techniques for visualising complex historical datasets."
  },
  {
    "objectID": "index.html#outputs",
    "href": "index.html#outputs",
    "title": "Nineteenth-Century Criminal Tattoos",
    "section": "Outputs",
    "text": "Outputs\n\nAlker, Zoe and Robert Shoemaker. ‘Convicts and the Cultural Significance of Tattooing in Nineteenth-Century Britain’. Journal of British Studies 61, no 4 (2022), 835–62. https://doi.org/10.1017/jbr.2022.117\nHow tattoos became fashionable in Victorian England, The Conversation (December 2019)\nConvict Tattoos research page, Digital Panopticon (2020)\nSelected visualisations for the Digital Panopticon Visualisations Gallery\nThe data was incorporated into the Digital Panopticon database: see Tattoos, 1793-1925 (2020)\nPublic release of the data: Tattoos in the Digital Panopticon database, 1793-1925 (December 2020)\n\nongoing:\n\nan occasional series of posts on this blog to introduce the data and methods for its analysis and visualisation (December 2020 onwards)\nfurther journal articles"
  },
  {
    "objectID": "index.html#further-reading",
    "href": "index.html#further-reading",
    "title": "Nineteenth-Century Criminal Tattoos",
    "section": "Further reading",
    "text": "Further reading\n\nAnderson, Clare, ‘Empire, Boundaries, and Bodies: colonial tattooing practices’ in Michael Sappol and Stephen P. Rice (eds), A cultural history of the human body in the age of empire (Oxford, 2010)\nBreathnach, Ciara and Elaine Farrell, ‘“Indelible Characters”: Tattoos, Power and the Late Nineteenth-Century Irish Convict Body’, Cultural and Social History, 12.2 (2015)\nCaplan, Jane, Written on the body: the tattoo in European and American history (London, 2000)\nKent, David, ‘Decorative bodies: The significance of convicts’ tattoos’, Journal of Australian Studies, 21 (1997)\nMaxwell-Stewart, Hamish and James Bradley, ‘Convict tattoos: Tales of freedom and coercion’ in M Field and T Millett (eds), Convict Love Tokens (1998)\nMaxwell-Stewart, Hamish and James Bradley, ‘Power, Observation and the Tattooed Convict’ in Australian Studies, 12.1 (1997)"
  },
  {
    "objectID": "index.html#credits",
    "href": "index.html#credits",
    "title": "Nineteenth-Century Criminal Tattoos",
    "section": "Credits",
    "text": "Credits\nThe project was funded by British Academy/Jisc Digital Research in the Humanities from 2018 to 2019.\nThe project directors are Robert Shoemaker, University of Sheffield, and Zoe Alker, University of Liverpool.\nProject technical development is carried out by the Digital Humanities Institute | Sheffield • Project webpage.\nThis blog has been built by Sharon Howard, with a little help from RStudio, Blogdown, Markdown and Github."
  },
  {
    "objectID": "index.html#re-use",
    "href": "index.html#re-use",
    "title": "Nineteenth-Century Criminal Tattoos",
    "section": "Re-use",
    "text": "Re-use\nThis website is licensed under a Creative Commons Attribution 4.0 International License."
  },
  {
    "objectID": "index.html#posts",
    "href": "index.html#posts",
    "title": "Nineteenth-Century Criminal Tattoos",
    "section": "Posts",
    "text": "Posts"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "Resources for R",
    "section": "",
    "text": "These are all (at the time of writing) freely available online resources."
  },
  {
    "objectID": "resources.html#general",
    "href": "resources.html#general",
    "title": "Resources for R",
    "section": "General",
    "text": "General\n\nCRAN - The Comprehensive R Archive Network\nRStudio\nStackOverflow posts tagged [R]"
  },
  {
    "objectID": "resources.html#tutorials",
    "href": "resources.html#tutorials",
    "title": "Resources for R",
    "section": "Tutorials",
    "text": "Tutorials\n\ngetting started\n\nExcel vs R: A Brief Introduction to R - why to use R for data analysis instead of spreadsheets, and how to get started, using a historical source as an example\n\nProgramming Historian lessons (a selection):\n\nR Basics with Tabular Data\nBasic Text Processing in R\nData Wrangling and Management in R\n\n\n\nmore substantial\n\nR for Data Science - the textbook for “Tidy” R.\nText Mining with R\n\n\n\nfocused on doing history with R\n\nComputational Historical Thinking With Applications in R\nDigital History Methods in R\nCorrespondence Analysis for Historical Research with R\nA Short Guide to Historical Newspaper Data Using R"
  },
  {
    "objectID": "resources.html#data-visualisation",
    "href": "resources.html#data-visualisation",
    "title": "Resources for R",
    "section": "Data visualisation",
    "text": "Data visualisation\n\nggplot2 documentation\nggplot2: elegant graphics for data analysis\nData visualization: a practical introduction\nFundamentals of data visualization"
  },
  {
    "objectID": "resources.html#statistics",
    "href": "resources.html#statistics",
    "title": "Resources for R",
    "section": "Statistics",
    "text": "Statistics\n\nStatistics for the Humanities\nr-statistics.co\nModern Dive: An Introduction to Statistical and Data Sciences via R\nStatistical Rethinking with brms, ggplot2 and the tidyverse\nR-Tutorial"
  },
  {
    "objectID": "resources.html#blogging",
    "href": "resources.html#blogging",
    "title": "Resources for R",
    "section": "Blogging",
    "text": "Blogging\n\nblogdown package (uses Hugo)\nBuilding a Blog with Blogdown and GitHub"
  },
  {
    "objectID": "resources.html#reproducible-research",
    "href": "resources.html#reproducible-research",
    "title": "Resources for R",
    "section": "Reproducible research",
    "text": "Reproducible research\n\nThe Practice of Reproducible Research\nSustainable Authorship in Plain Text using Pandoc and Markdown\nR for Reproducible Research"
  },
  {
    "objectID": "resources.html#other-coding-resources",
    "href": "resources.html#other-coding-resources",
    "title": "Resources for R",
    "section": "Other coding resources",
    "text": "Other coding resources\n\nTeaching yourself to code in DH"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Posts Archive",
    "section": "",
    "text": "Come TogetheR: Combining data tables in R with dplyr join verbs\n\n\n\n\n\n\n\n\n\n19 Jun 2021\n\n\n\n\n\n\n\n\nTidying Tattoos: Handling missing data and non-tidy columns\n\n\n\n\n\n\n\n\n\n15 May 2021\n\n\n\n\n\n\n\n\nA first look at tattoos in the Digital Panopticon\n\n\n\n\n\n\n\n\n\n12 Apr 2021\n\n\n\n\n\n\n\n\nData Release: Tattoos in the Digital Panopticon Database, 1793-1925\n\n\n\n\n\n\n\n\n\n21 Dec 2020\n\n\n\n\n\n\n\n\nTattoos Hackathon, 16 April 2019\n\n\n\n\n\n\n\n\n\n21 May 2019\n\n\n\n\n\n\n\n\nIntroducing the Tattoos Project\n\n\n\n\n\n\n\n\n\n3 Nov 2018\n\n\n\n\n\n\nNo matching items"
  }
]